{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import *\n",
    "from funcs import *\n",
    "\n",
    "from mobnet import model_mobnet\n",
    "from training_functions import *\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "data_path = 'data_2020/'\n",
    "train_csv = data_path + 'evaluation_setup/fold1_train.csv'\n",
    "val_csv = data_path + 'evaluation_setup/fold1_evaluate.csv'\n",
    "feat_path = 'features/logmel128_scaled_d_dd/'\n",
    "experiments = 'exp_mobnet'\n",
    "\n",
    "if not os.path.exists(experiments):\n",
    "    os.makedirs(experiments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 461, 6)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 64, 461, 6)   0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 64, 461, 6)   0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 231, 32)  1760        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 32, 231, 32)  1760        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 231, 32)  128         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 32, 231, 32)  128         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 32, 231, 32)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 32, 231, 32)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 231, 64)  2112        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 32, 231, 64)  2112        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 231, 64)  256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 32, 231, 64)  256         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 32, 231, 64)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 32, 231, 64)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_19 (DepthwiseC (None, 16, 116, 64)  640         activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_28 (DepthwiseC (None, 16, 116, 64)  640         activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 16, 116, 64)  256         depthwise_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 16, 116, 64)  256         depthwise_conv2d_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 116, 64)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 16, 116, 64)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 116, 32)  2080        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 116, 32)  2080        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 16, 116, 32)  128         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 16, 116, 32)  128         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 116, 64)  2112        batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 116, 64)  2112        batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 16, 116, 64)  256         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 16, 116, 64)  256         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 116, 64)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 116, 64)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_20 (DepthwiseC (None, 16, 116, 64)  640         activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_29 (DepthwiseC (None, 16, 116, 64)  640         activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 16, 116, 64)  256         depthwise_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 16, 116, 64)  256         depthwise_conv2d_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 116, 64)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 16, 116, 64)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 116, 32)  2080        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 116, 32)  2080        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 16, 116, 32)  128         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 16, 116, 32)  128         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 116, 32)  0           batch_normalization_68[0][0]     \n",
      "                                                                 batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 16, 116, 32)  0           batch_normalization_97[0][0]     \n",
      "                                                                 batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 116, 64)  2112        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 116, 64)  2112        add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 16, 116, 64)  256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 16, 116, 64)  256         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 116, 64)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 16, 116, 64)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_21 (DepthwiseC (None, 16, 116, 64)  640         activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_30 (DepthwiseC (None, 16, 116, 64)  640         activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 16, 116, 64)  256         depthwise_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 16, 116, 64)  256         depthwise_conv2d_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 116, 64)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 16, 116, 64)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 116, 32)  2080        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 16, 116, 32)  2080        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 16, 116, 32)  128         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 116, 32)  128         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 116, 32)  0           batch_normalization_71[0][0]     \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 16, 116, 32)  0           batch_normalization_100[0][0]    \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 116, 64)  2112        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 16, 116, 64)  2112        add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 16, 116, 64)  256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 116, 64)  256         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 116, 64)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 16, 116, 64)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_22 (DepthwiseC (None, 8, 58, 64)    640         activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_31 (DepthwiseC (None, 8, 58, 64)    640         activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 58, 64)    256         depthwise_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 8, 58, 64)    256         depthwise_conv2d_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 58, 64)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 58, 64)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 58, 40)    2600        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 58, 40)    2600        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 58, 40)    160         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 8, 58, 40)    160         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 58, 80)    3280        batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 58, 80)    3280        batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 58, 80)    320         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 8, 58, 80)    320         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 58, 80)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 58, 80)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_23 (DepthwiseC (None, 8, 58, 80)    800         activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_32 (DepthwiseC (None, 8, 58, 80)    800         activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 58, 80)    320         depthwise_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 8, 58, 80)    320         depthwise_conv2d_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 58, 80)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 58, 80)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 58, 40)    3240        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 58, 40)    3240        activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 58, 40)    160         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 8, 58, 40)    160         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 58, 40)    0           batch_normalization_77[0][0]     \n",
      "                                                                 batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 58, 40)    0           batch_normalization_106[0][0]    \n",
      "                                                                 batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 58, 80)    3280        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 58, 80)    3280        add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 58, 80)    320         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 8, 58, 80)    320         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 58, 80)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 58, 80)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_24 (DepthwiseC (None, 8, 58, 80)    800         activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_33 (DepthwiseC (None, 8, 58, 80)    800         activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 58, 80)    320         depthwise_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 8, 58, 80)    320         depthwise_conv2d_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 58, 80)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 58, 80)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 58, 40)    3240        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 58, 40)    3240        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 58, 40)    160         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 8, 58, 40)    160         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 58, 40)    0           batch_normalization_80[0][0]     \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 8, 58, 40)    0           batch_normalization_109[0][0]    \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 58, 80)    3280        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 58, 80)    3280        add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 58, 80)    320         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 8, 58, 80)    320         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 58, 80)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 58, 80)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_25 (DepthwiseC (None, 4, 29, 80)    800         activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_34 (DepthwiseC (None, 4, 29, 80)    800         activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 4, 29, 80)    320         depthwise_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 4, 29, 80)    320         depthwise_conv2d_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 4, 29, 80)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 4, 29, 80)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 4, 29, 48)    3888        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 4, 29, 48)    3888        activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 4, 29, 48)    192         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 4, 29, 48)    192         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 4, 29, 96)    4704        batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 4, 29, 96)    4704        batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 4, 29, 96)    384         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 4, 29, 96)    384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 4, 29, 96)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 4, 29, 96)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_26 (DepthwiseC (None, 4, 29, 96)    960         activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_35 (DepthwiseC (None, 4, 29, 96)    960         activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 4, 29, 96)    384         depthwise_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 4, 29, 96)    384         depthwise_conv2d_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 4, 29, 96)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 4, 29, 96)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 4, 29, 48)    4656        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 4, 29, 48)    4656        activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 4, 29, 48)    192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 4, 29, 48)    192         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 4, 29, 48)    0           batch_normalization_86[0][0]     \n",
      "                                                                 batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 4, 29, 48)    0           batch_normalization_115[0][0]    \n",
      "                                                                 batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 4, 29, 96)    4704        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 4, 29, 96)    4704        add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 4, 29, 96)    384         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 4, 29, 96)    384         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 4, 29, 96)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 4, 29, 96)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_27 (DepthwiseC (None, 4, 29, 96)    960         activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_36 (DepthwiseC (None, 4, 29, 96)    960         activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 4, 29, 96)    384         depthwise_conv2d_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 4, 29, 96)    384         depthwise_conv2d_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 4, 29, 96)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 4, 29, 96)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 4, 29, 48)    4656        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 4, 29, 48)    4656        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 4, 29, 48)    192         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 4, 29, 48)    192         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 4, 29, 48)    0           batch_normalization_89[0][0]     \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 4, 29, 48)    0           batch_normalization_118[0][0]    \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 4, 29, 56)    2744        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 4, 29, 56)    2744        add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 4, 29, 56)    224         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 4, 29, 56)    224         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 4, 29, 56)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 4, 29, 56)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 29, 56)    0           activation_62[0][0]              \n",
      "                                                                 activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 8, 29, 56)    112         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 29, 56)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 29, 48)    2688        activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Dropout (Dropout)               (None, 8, 29, 48)    0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 8, 29, 48)    96          Dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 29, 3)     144         batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 8, 29, 3)     6           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 3)            0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3)            0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 152,838\n",
      "Trainable params: 145,328\n",
      "Non-trainable params: 7,510\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# random sample data, to keep all three classes have similar number of training samples\n",
    "total_csv = balance_class_data(train_csv, experiments)\n",
    "\n",
    "num_audio_channels = 2\n",
    "num_freq_bin = 128\n",
    "num_time_bin = 461\n",
    "num_classes = 3\n",
    "max_lr = 0.1\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "mixup_alpha = 0.4\n",
    "sample_num = len(open(train_csv, 'r').readlines()) - 1\n",
    "no = 0\n",
    "\n",
    "data_val, y_val = load_data_2020(feat_path, val_csv, num_freq_bin, 'logmel')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "model = model_mobnet(num_classes, input_shape=[num_freq_bin, num_time_bin, 3*num_audio_channels], num_filters=24, wd=1e-3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = SGD(lr=max_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy']) #ori\n",
    "\n",
    "model.summary()\n",
    "\n",
    "lr_scheduler = LR_WarmRestart(nbatch=np.ceil(sample_num/batch_size), Tmult=2,\n",
    "                              initial_lr=max_lr, min_lr=max_lr*1e-4,\n",
    "                              epochs_restart = [3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0]) \n",
    "save_path = experiments + \"/model-mixup_alpha:{}-max_lr:{}-total_epochs:{}-no:{}.hdf5\".format(mixup_alpha, max_lr, num_epochs, no)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(save_path, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks = [lr_scheduler, checkpoint]\n",
    "\n",
    "train_data_generator = Generator_balanceclass_timefreqmask_nocropping_splitted(feat_path, train_csv, total_csv, experiments, num_freq_bin, \n",
    "                              batch_size=batch_size,\n",
    "                              alpha=mixup_alpha, splitted_num=4)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/50\n",
      "288/288 [==============================] - 49s 171ms/step - loss: 0.8670 - acc: 0.7045 - val_loss: 0.7441 - val_acc: 0.7078\n",
      "\n",
      "LR:0.050278\n",
      "\n",
      "Epoch 00001: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 2/50\n",
      "288/288 [==============================] - 33s 115ms/step - loss: 0.7083 - acc: 0.8099 - val_loss: 0.5228 - val_acc: 0.8719\n",
      "\n",
      "LR:0.000011\n",
      "\n",
      "Epoch 00002: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 3/50\n",
      "288/288 [==============================] - 38s 132ms/step - loss: 0.7010 - acc: 0.7997 - val_loss: 0.9523 - val_acc: 0.4600\n",
      "\n",
      "LR:0.085453\n",
      "\n",
      "Epoch 00003: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 4/50\n",
      "288/288 [==============================] - 39s 135ms/step - loss: 0.6527 - acc: 0.8212 - val_loss: 0.5115 - val_acc: 0.8753\n",
      "\n",
      "LR:0.050141\n",
      "\n",
      "Epoch 00004: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 5/50\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.6092 - acc: 0.8498 - val_loss: 0.6007 - val_acc: 0.8507\n",
      "\n",
      "LR:0.014750\n",
      "\n",
      "Epoch 00005: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 6/50\n",
      "288/288 [==============================] - 38s 133ms/step - loss: 0.5914 - acc: 0.8714 - val_loss: 0.4109 - val_acc: 0.9130\n",
      "\n",
      "LR:0.000010\n",
      "\n",
      "Epoch 00006: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 7/50\n",
      "288/288 [==============================] - 38s 133ms/step - loss: 0.6257 - acc: 0.8429 - val_loss: 0.5535 - val_acc: 0.8086\n",
      "\n",
      "LR:0.096220\n",
      "\n",
      "Epoch 00007: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 8/50\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.6145 - acc: 0.8537 - val_loss: 0.7177 - val_acc: 0.6456\n",
      "\n",
      "LR:0.085405\n",
      "\n",
      "Epoch 00008: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 9/50\n",
      "288/288 [==============================] - 39s 137ms/step - loss: 0.5934 - acc: 0.8675 - val_loss: 0.6277 - val_acc: 0.7477\n",
      "\n",
      "LR:0.069200\n",
      "\n",
      "Epoch 00009: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 10/50\n",
      "288/288 [==============================] - 38s 133ms/step - loss: 0.5755 - acc: 0.8805 - val_loss: 0.4627 - val_acc: 0.9008\n",
      "\n",
      "LR:0.050073\n",
      "\n",
      "Epoch 00010: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 11/50\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.5654 - acc: 0.8912 - val_loss: 0.6087 - val_acc: 0.8194\n",
      "\n",
      "LR:0.030936\n",
      "\n",
      "Epoch 00011: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 12/50\n",
      "288/288 [==============================] - 38s 133ms/step - loss: 0.5485 - acc: 0.9041 - val_loss: 0.4071 - val_acc: 0.9180\n",
      "\n",
      "LR:0.014701\n",
      "\n",
      "Epoch 00012: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 13/50\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.5433 - acc: 0.9052 - val_loss: 0.4141 - val_acc: 0.9059\n",
      "\n",
      "LR:0.003842\n",
      "\n",
      "Epoch 00013: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 14/50\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.5366 - acc: 0.9103 - val_loss: 0.3738 - val_acc: 0.9309\n",
      "\n",
      "LR:0.000010\n",
      "\n",
      "Epoch 00014: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 15/50\n",
      "288/288 [==============================] - 38s 133ms/step - loss: 0.5755 - acc: 0.8792 - val_loss: 0.7943 - val_acc: 0.6253\n",
      "\n",
      "LR:0.099046\n",
      "\n",
      "Epoch 00015: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 16/50\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.5739 - acc: 0.8802 - val_loss: 0.5583 - val_acc: 0.7596\n",
      "\n",
      "LR:0.096207\n",
      "\n",
      "Epoch 00016: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 17/50\n",
      "288/288 [==============================] - 38s 134ms/step - loss: 0.5554 - acc: 0.8955 - val_loss: 0.4896 - val_acc: 0.8977\n",
      "\n",
      "LR:0.091593\n",
      "\n",
      "Epoch 00017: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 18/50\n",
      "288/288 [==============================] - 39s 137ms/step - loss: 0.5555 - acc: 0.8981 - val_loss: 0.7554 - val_acc: 0.6526\n",
      "\n",
      "LR:0.085381\n",
      "\n",
      "Epoch 00018: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 19/50\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.5443 - acc: 0.9017 - val_loss: 0.5731 - val_acc: 0.8270\n",
      "\n",
      "LR:0.077809\n",
      "\n",
      "Epoch 00019: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 20/50\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.5393 - acc: 0.9029 - val_loss: 0.5142 - val_acc: 0.8607\n",
      "\n",
      "LR:0.069169\n",
      "\n",
      "Epoch 00020: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 21/50\n",
      "288/288 [==============================] - 38s 134ms/step - loss: 0.5313 - acc: 0.9107 - val_loss: 0.6633 - val_acc: 0.7204\n",
      "\n",
      "LR:0.059792\n",
      "\n",
      "Epoch 00021: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 22/50\n",
      "288/288 [==============================] - 38s 134ms/step - loss: 0.5226 - acc: 0.9160 - val_loss: 0.4518 - val_acc: 0.8977\n",
      "\n",
      "LR:0.050039\n",
      "\n",
      "Epoch 00022: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 23/50\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.5191 - acc: 0.9198 - val_loss: 0.3984 - val_acc: 0.9049\n",
      "\n",
      "LR:0.040285\n",
      "\n",
      "Epoch 00023: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 24/50\n",
      "288/288 [==============================] - 38s 133ms/step - loss: 0.5134 - acc: 0.9219 - val_loss: 0.3933 - val_acc: 0.9283\n",
      "\n",
      "LR:0.030904\n",
      "\n",
      "Epoch 00024: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 25/50\n",
      "288/288 [==============================] - 39s 135ms/step - loss: 0.5072 - acc: 0.9306 - val_loss: 0.4133 - val_acc: 0.9137\n",
      "\n",
      "LR:0.022258\n",
      "\n",
      "Epoch 00025: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 26/50\n",
      "288/288 [==============================] - 40s 138ms/step - loss: 0.5044 - acc: 0.9315 - val_loss: 0.3828 - val_acc: 0.9341\n",
      "\n",
      "LR:0.014677\n",
      "\n",
      "Epoch 00026: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 27/50\n",
      "288/288 [==============================] - 38s 134ms/step - loss: 0.5012 - acc: 0.9335 - val_loss: 0.3749 - val_acc: 0.9293\n",
      "\n",
      "LR:0.008455\n",
      "\n",
      "Epoch 00027: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 28/50\n",
      "288/288 [==============================] - 39s 135ms/step - loss: 0.4909 - acc: 0.9370 - val_loss: 0.3547 - val_acc: 0.9372\n",
      "\n",
      "LR:0.003829\n",
      "\n",
      "Epoch 00028: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 29/50\n",
      "288/288 [==============================] - 39s 135ms/step - loss: 0.4957 - acc: 0.9312 - val_loss: 0.3516 - val_acc: 0.9391\n",
      "\n",
      "LR:0.000977\n",
      "\n",
      "Epoch 00029: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 30/50\n",
      "288/288 [==============================] - 38s 133ms/step - loss: 0.4969 - acc: 0.9380 - val_loss: 0.3472 - val_acc: 0.9393\n",
      "\n",
      "LR:0.000010\n",
      "\n",
      "Epoch 00030: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 31/50\n",
      "288/288 [==============================] - 39s 135ms/step - loss: 0.5254 - acc: 0.9116 - val_loss: 0.7002 - val_acc: 0.6817\n",
      "\n",
      "LR:0.099761\n",
      "\n",
      "Epoch 00031: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 32/50\n",
      "288/288 [==============================] - 38s 132ms/step - loss: 0.5264 - acc: 0.9102 - val_loss: 0.5065 - val_acc: 0.8843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR:0.099043\n",
      "\n",
      "Epoch 00032: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 33/50\n",
      "288/288 [==============================] - 38s 133ms/step - loss: 0.5251 - acc: 0.9141 - val_loss: 0.5516 - val_acc: 0.7811\n",
      "\n",
      "LR:0.097852\n",
      "\n",
      "Epoch 00033: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 34/50\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.5199 - acc: 0.9186 - val_loss: 0.5065 - val_acc: 0.9106\n",
      "\n",
      "LR:0.096201\n",
      "\n",
      "Epoch 00034: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 35/50\n",
      "288/288 [==============================] - 39s 135ms/step - loss: 0.5125 - acc: 0.9265 - val_loss: 0.4857 - val_acc: 0.8676\n",
      "\n",
      "LR:0.094105\n",
      "\n",
      "Epoch 00035: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 36/50\n",
      "288/288 [==============================] - 40s 139ms/step - loss: 0.5104 - acc: 0.9239 - val_loss: 0.4365 - val_acc: 0.8812\n",
      "\n",
      "LR:0.091584\n",
      "\n",
      "Epoch 00036: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 37/50\n",
      "288/288 [==============================] - 38s 133ms/step - loss: 0.5111 - acc: 0.9252 - val_loss: 0.5249 - val_acc: 0.8366\n",
      "\n",
      "LR:0.088662\n",
      "\n",
      "Epoch 00037: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 38/50\n",
      "288/288 [==============================] - 39s 135ms/step - loss: 0.5047 - acc: 0.9296 - val_loss: 0.3968 - val_acc: 0.9135\n",
      "\n",
      "LR:0.085369\n",
      "\n",
      "Epoch 00038: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 39/50\n",
      "288/288 [==============================] - 38s 132ms/step - loss: 0.5068 - acc: 0.9270 - val_loss: 0.4685 - val_acc: 0.8688\n",
      "\n",
      "LR:0.081735\n",
      "\n",
      "Epoch 00039: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 40/50\n",
      "288/288 [==============================] - 39s 135ms/step - loss: 0.5096 - acc: 0.9247 - val_loss: 0.4616 - val_acc: 0.8843\n",
      "\n",
      "LR:0.077795\n",
      "\n",
      "Epoch 00040: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 41/50\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.4951 - acc: 0.9307 - val_loss: 0.4399 - val_acc: 0.8989\n",
      "\n",
      "LR:0.073588\n",
      "\n",
      "Epoch 00041: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 42/50\n",
      "288/288 [==============================] - 38s 133ms/step - loss: 0.4922 - acc: 0.9354 - val_loss: 0.4253 - val_acc: 0.9152\n",
      "\n",
      "LR:0.069153\n",
      "\n",
      "Epoch 00042: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 43/50\n",
      "288/288 [==============================] - 39s 135ms/step - loss: 0.4972 - acc: 0.9360 - val_loss: 0.3815 - val_acc: 0.9178\n",
      "\n",
      "LR:0.064534\n",
      "\n",
      "Epoch 00043: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 44/50\n",
      "288/288 [==============================] - 40s 137ms/step - loss: 0.4870 - acc: 0.9375 - val_loss: 0.3969 - val_acc: 0.9123\n",
      "\n",
      "LR:0.059775\n",
      "\n",
      "Epoch 00044: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 45/50\n",
      "288/288 [==============================] - 38s 133ms/step - loss: 0.4926 - acc: 0.9365 - val_loss: 0.3575 - val_acc: 0.9364\n",
      "\n",
      "LR:0.054922\n",
      "\n",
      "Epoch 00045: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 46/50\n",
      "288/288 [==============================] - 38s 134ms/step - loss: 0.4800 - acc: 0.9430 - val_loss: 0.3637 - val_acc: 0.9329\n",
      "\n",
      "LR:0.050022\n",
      "\n",
      "Epoch 00046: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 47/50\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.4801 - acc: 0.9431 - val_loss: 0.4339 - val_acc: 0.9221\n",
      "\n",
      "LR:0.045122\n",
      "\n",
      "Epoch 00047: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 48/50\n",
      "288/288 [==============================] - 39s 136ms/step - loss: 0.4811 - acc: 0.9399 - val_loss: 0.4966 - val_acc: 0.8566\n",
      "\n",
      "LR:0.040268\n",
      "\n",
      "Epoch 00048: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 49/50\n",
      "288/288 [==============================] - 38s 132ms/step - loss: 0.4819 - acc: 0.9403 - val_loss: 0.3441 - val_acc: 0.9391\n",
      "\n",
      "LR:0.035509\n",
      "\n",
      "Epoch 00049: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n",
      "Epoch 50/50\n",
      "288/288 [==============================] - 38s 132ms/step - loss: 0.4796 - acc: 0.9438 - val_loss: 0.4530 - val_acc: 0.8798\n",
      "\n",
      "LR:0.030888\n",
      "\n",
      "Epoch 00050: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:50-no:0.hdf5\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_data_generator,\n",
    "                              validation_data=(data_val, y_val),\n",
    "                              epochs=num_epochs, \n",
    "                              verbose=1, \n",
    "                              workers=4,\n",
    "                              max_queue_size = 100,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=np.ceil(sample_num/batch_size)\n",
    "                              ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 461, 6)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 64, 461, 6)   0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 64, 461, 6)   0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 231, 32)  1760        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 231, 32)  1760        lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 231, 32)  128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 231, 32)  128         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 231, 32)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 231, 32)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 231, 64)  2112        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 231, 64)  2112        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 231, 64)  256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 231, 64)  256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 231, 64)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 231, 64)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_1 (DepthwiseCo (None, 16, 116, 64)  640         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_10 (DepthwiseC (None, 16, 116, 64)  640         activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 116, 64)  256         depthwise_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 116, 64)  256         depthwise_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16, 116, 64)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 116, 64)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 16, 116, 32)  2080        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 116, 32)  2080        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 16, 116, 32)  128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 116, 32)  128         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 116, 64)  2112        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 116, 64)  2112        batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 116, 64)  256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 116, 64)  256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 116, 64)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 116, 64)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_2 (DepthwiseCo (None, 16, 116, 64)  640         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_11 (DepthwiseC (None, 16, 116, 64)  640         activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 116, 64)  256         depthwise_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 116, 64)  256         depthwise_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 116, 64)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 116, 64)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 116, 32)  2080        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 116, 32)  2080        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 116, 32)  128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 116, 32)  128         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 16, 116, 32)  0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 116, 32)  0           batch_normalization_36[0][0]     \n",
      "                                                                 batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 116, 64)  2112        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 116, 64)  2112        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 116, 64)  256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 116, 64)  256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 116, 64)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 116, 64)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_3 (DepthwiseCo (None, 16, 116, 64)  640         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_12 (DepthwiseC (None, 16, 116, 64)  640         activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 116, 64)  256         depthwise_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 116, 64)  256         depthwise_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 116, 64)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 116, 64)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 116, 32)  2080        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 116, 32)  2080        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 116, 32)  128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 116, 32)  128         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 116, 32)  0           batch_normalization_10[0][0]     \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 116, 32)  0           batch_normalization_39[0][0]     \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 116, 64)  2112        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 116, 64)  2112        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 116, 64)  256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 116, 64)  256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 116, 64)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 116, 64)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_4 (DepthwiseCo (None, 8, 58, 64)    640         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_13 (DepthwiseC (None, 8, 58, 64)    640         activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 58, 64)    256         depthwise_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 58, 64)    256         depthwise_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 58, 64)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 58, 64)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 58, 40)    2600        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 8, 58, 40)    2600        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 58, 40)    160         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 58, 40)    160         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 58, 80)    3280        batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 58, 80)    3280        batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 58, 80)    320         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 58, 80)    320         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 58, 80)    0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 58, 80)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_5 (DepthwiseCo (None, 8, 58, 80)    800         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_14 (DepthwiseC (None, 8, 58, 80)    800         activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 58, 80)    320         depthwise_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 58, 80)    320         depthwise_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 58, 80)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 58, 80)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 58, 40)    3240        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 58, 40)    3240        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 58, 40)    160         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 58, 40)    160         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 58, 40)    0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 58, 40)    0           batch_normalization_45[0][0]     \n",
      "                                                                 batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 58, 80)    3280        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 58, 80)    3280        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 58, 80)    320         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 58, 80)    320         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 58, 80)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 58, 80)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_6 (DepthwiseCo (None, 8, 58, 80)    800         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_15 (DepthwiseC (None, 8, 58, 80)    800         activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 58, 80)    320         depthwise_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 58, 80)    320         depthwise_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 58, 80)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 58, 80)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 58, 40)    3240        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 58, 40)    3240        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 58, 40)    160         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 58, 40)    160         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 58, 40)    0           batch_normalization_19[0][0]     \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 58, 40)    0           batch_normalization_48[0][0]     \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 58, 80)    3280        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 58, 80)    3280        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 58, 80)    320         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 58, 80)    320         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 58, 80)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 58, 80)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_7 (DepthwiseCo (None, 4, 29, 80)    800         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_16 (DepthwiseC (None, 4, 29, 80)    800         activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 4, 29, 80)    320         depthwise_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 4, 29, 80)    320         depthwise_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 29, 80)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 29, 80)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 29, 48)    3888        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 4, 29, 48)    3888        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 4, 29, 48)    192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 4, 29, 48)    192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 29, 96)    4704        batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 4, 29, 96)    4704        batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 4, 29, 96)    384         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 4, 29, 96)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 29, 96)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 4, 29, 96)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_8 (DepthwiseCo (None, 4, 29, 96)    960         activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_17 (DepthwiseC (None, 4, 29, 96)    960         activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 4, 29, 96)    384         depthwise_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 4, 29, 96)    384         depthwise_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 29, 96)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 4, 29, 96)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 4, 29, 48)    4656        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 4, 29, 48)    4656        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 4, 29, 48)    192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 4, 29, 48)    192         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 29, 48)    0           batch_normalization_25[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 4, 29, 48)    0           batch_normalization_54[0][0]     \n",
      "                                                                 batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 29, 96)    4704        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 4, 29, 96)    4704        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 4, 29, 96)    384         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 4, 29, 96)    384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 29, 96)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 4, 29, 96)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_9 (DepthwiseCo (None, 4, 29, 96)    960         activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_18 (DepthwiseC (None, 4, 29, 96)    960         activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 29, 96)    384         depthwise_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 4, 29, 96)    384         depthwise_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 29, 96)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 29, 96)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 29, 48)    4656        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 4, 29, 48)    4656        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 4, 29, 48)    192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 4, 29, 48)    192         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 29, 48)    0           batch_normalization_28[0][0]     \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 29, 48)    0           batch_normalization_57[0][0]     \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 29, 56)    2744        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 4, 29, 56)    2744        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 4, 29, 56)    224         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 4, 29, 56)    224         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 4, 29, 56)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 29, 56)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 29, 56)    0           activation_20[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 29, 56)    112         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 29, 56)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 29, 48)    2688        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Dropout (Dropout)               (None, 8, 29, 48)    0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 29, 48)    96          Dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 29, 3)     144         batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 29, 3)     6           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 3)            0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 3)            0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 152,838\n",
      "Trainable params: 145,328\n",
      "Non-trainable params: 7,510\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# random sample data, to keep all three classes have similar number of training samples\n",
    "total_csv = balance_class_data(train_csv, experiments)\n",
    "\n",
    "num_audio_channels = 2\n",
    "num_freq_bin = 128\n",
    "num_time_bin = 461\n",
    "num_classes = 3\n",
    "max_lr = 0.1\n",
    "batch_size = 32\n",
    "num_epochs = 30\n",
    "mixup_alpha = 0.4\n",
    "sample_num = len(open(train_csv, 'r').readlines()) - 1\n",
    "no = 1\n",
    "\n",
    "data_val, y_val = load_data_2020(feat_path, val_csv, num_freq_bin, 'logmel')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "model = model_mobnet(num_classes, input_shape=[num_freq_bin, num_time_bin, 3*num_audio_channels], num_filters=24, wd=1e-3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = SGD(lr=max_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy']) #ori\n",
    "\n",
    "model.summary()\n",
    "\n",
    "lr_scheduler = LR_WarmRestart(nbatch=np.ceil(sample_num/batch_size), Tmult=2,\n",
    "                              initial_lr=max_lr, min_lr=max_lr*1e-4,\n",
    "                              epochs_restart = [3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0]) \n",
    "save_path = experiments + \"/model-mixup_alpha:{}-max_lr:{}-total_epochs:{}-no:{}.hdf5\".format(mixup_alpha, max_lr, num_epochs, no)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(save_path, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks = [lr_scheduler, checkpoint]\n",
    "\n",
    "train_data_generator = Generator_balanceclass_timefreqmask_nocropping_splitted(feat_path, train_csv, total_csv, experiments, num_freq_bin, \n",
    "                              batch_size=batch_size,\n",
    "                              alpha=mixup_alpha, splitted_num=4)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /scratch-local/kilic/anaconda3/envs/d20-keras/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/30\n",
      "288/288 [==============================] - 48s 165ms/step - loss: 0.8641 - acc: 0.7067 - val_loss: 0.8921 - val_acc: 0.5505\n",
      "\n",
      "LR:0.050278\n",
      "\n",
      "Epoch 00001: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:30-no:1.hdf5\n",
      "Epoch 2/30\n",
      "288/288 [==============================] - 33s 115ms/step - loss: 0.6995 - acc: 0.8115 - val_loss: 0.5720 - val_acc: 0.8509\n",
      "\n",
      "LR:0.000011\n",
      "\n",
      "Epoch 00002: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:30-no:1.hdf5\n",
      "Epoch 3/30\n",
      "288/288 [==============================] - 38s 132ms/step - loss: 0.6974 - acc: 0.7992 - val_loss: 1.0023 - val_acc: 0.4712\n",
      "\n",
      "LR:0.085453\n",
      "\n",
      "Epoch 00003: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:30-no:1.hdf5\n",
      "Epoch 4/30\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.6535 - acc: 0.8280 - val_loss: 0.5586 - val_acc: 0.8337\n",
      "\n",
      "LR:0.050141\n",
      "\n",
      "Epoch 00004: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:30-no:1.hdf5\n",
      "Epoch 5/30\n",
      "288/288 [==============================] - 38s 133ms/step - loss: 0.6145 - acc: 0.8467 - val_loss: 0.4950 - val_acc: 0.8855\n",
      "\n",
      "LR:0.014750\n",
      "\n",
      "Epoch 00005: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:30-no:1.hdf5\n",
      "Epoch 6/30\n",
      "288/288 [==============================] - 39s 134ms/step - loss: 0.5941 - acc: 0.8681 - val_loss: 0.4305 - val_acc: 0.8975\n",
      "\n",
      "LR:0.000010\n",
      "\n",
      "Epoch 00006: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:30-no:1.hdf5\n",
      "Epoch 7/30\n",
      "288/288 [==============================] - 39s 135ms/step - loss: 0.6232 - acc: 0.8415 - val_loss: 0.9395 - val_acc: 0.5481\n",
      "\n",
      "LR:0.096220\n",
      "\n",
      "Epoch 00007: saving model to exp_mobnet/model-mixup_alpha:0.4-max_lr:0.1-total_epochs:30-no:1.hdf5\n",
      "Epoch 8/30\n",
      "236/288 [=======================>......] - ETA: 5s - loss: 0.6100 - acc: 0.8524"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_data_generator,\n",
    "                              validation_data=(data_val, y_val),\n",
    "                              epochs=num_epochs, \n",
    "                              verbose=1, \n",
    "                              workers=4,\n",
    "                              max_queue_size = 100,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=np.ceil(sample_num/batch_size)\n",
    "                              ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample data, to keep all three classes have similar number of training samples\n",
    "total_csv = balance_class_data(train_csv, experiments)\n",
    "\n",
    "num_audio_channels = 2\n",
    "num_freq_bin = 128\n",
    "num_time_bin = 461\n",
    "num_classes = 3\n",
    "max_lr = 0.1\n",
    "batch_size = 32\n",
    "num_epochs = 500\n",
    "mixup_alpha = 0.4\n",
    "sample_num = len(open(train_csv, 'r').readlines()) - 1\n",
    "no = 2\n",
    "\n",
    "\n",
    "data_val, y_val = load_data_2020(feat_path, val_csv, num_freq_bin, 'logmel')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "model = model_mobnet(num_classes, input_shape=[num_freq_bin, num_time_bin, 3*num_audio_channels], num_filters=24, wd=1e-3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = SGD(lr=max_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy']) #ori\n",
    "\n",
    "model.summary()\n",
    "\n",
    "lr_scheduler = LR_WarmRestart(nbatch=np.ceil(sample_num/batch_size), Tmult=2,\n",
    "                              initial_lr=max_lr, min_lr=max_lr*1e-4,\n",
    "                              epochs_restart = [3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0]) \n",
    "save_path = experiments + \"/model-mixup_alpha:{}-max_lr:{}-total_epochs:{}-no:{}.hdf5\".format(mixup_alpha, max_lr, num_epochs, no)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(save_path, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks = [lr_scheduler, checkpoint]\n",
    "\n",
    "train_data_generator = Generator_balanceclass_timefreqmask_nocropping_splitted(feat_path, train_csv, total_csv, experiments, num_freq_bin, \n",
    "                              batch_size=batch_size,\n",
    "                              alpha=mixup_alpha, splitted_num=4)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_data_generator,\n",
    "                              validation_data=(data_val, y_val),\n",
    "                              epochs=num_epochs, \n",
    "                              verbose=1, \n",
    "                              workers=4,\n",
    "                              max_queue_size = 100,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=np.ceil(sample_num/batch_size)\n",
    "                              ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample data, to keep all three classes have similar number of training samples\n",
    "total_csv = balance_class_data(train_csv, experiments)\n",
    "\n",
    "num_audio_channels = 2\n",
    "num_freq_bin = 128\n",
    "num_time_bin = 461\n",
    "num_classes = 3\n",
    "max_lr = 0.1\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "mixup_alpha = 0.8\n",
    "sample_num = len(open(train_csv, 'r').readlines()) - 1\n",
    "no = 3\n",
    "\n",
    "\n",
    "data_val, y_val = load_data_2020(feat_path, val_csv, num_freq_bin, 'logmel')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "model = model_mobnet(num_classes, input_shape=[num_freq_bin, num_time_bin, 3*num_audio_channels], num_filters=24, wd=1e-3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = SGD(lr=max_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy']) #ori\n",
    "\n",
    "model.summary()\n",
    "\n",
    "lr_scheduler = LR_WarmRestart(nbatch=np.ceil(sample_num/batch_size), Tmult=2,\n",
    "                              initial_lr=max_lr, min_lr=max_lr*1e-4,\n",
    "                              epochs_restart = [3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0]) \n",
    "save_path = experiments + \"/model-mixup_alpha:{}-max_lr:{}-total_epochs:{}-no:{}.hdf5\".format(mixup_alpha, max_lr, num_epochs, no)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(save_path, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks = [lr_scheduler, checkpoint]\n",
    "\n",
    "train_data_generator = Generator_balanceclass_timefreqmask_nocropping_splitted(feat_path, train_csv, total_csv, experiments, num_freq_bin, \n",
    "                              batch_size=batch_size,\n",
    "                              alpha=mixup_alpha, splitted_num=4)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_data_generator,\n",
    "                              validation_data=(data_val, y_val),\n",
    "                              epochs=num_epochs, \n",
    "                              verbose=1, \n",
    "                              workers=4,\n",
    "                              max_queue_size = 100,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=np.ceil(sample_num/batch_size)\n",
    "                              ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample data, to keep all three classes have similar number of training samples\n",
    "total_csv = balance_class_data(train_csv, experiments)\n",
    "\n",
    "num_audio_channels = 2\n",
    "num_freq_bin = 128\n",
    "num_time_bin = 461\n",
    "num_classes = 3\n",
    "max_lr = 0.25\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "mixup_alpha = 0.4\n",
    "sample_num = len(open(train_csv, 'r').readlines()) - 1\n",
    "no = 4\n",
    "\n",
    "\n",
    "data_val, y_val = load_data_2020(feat_path, val_csv, num_freq_bin, 'logmel')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "model = model_mobnet(num_classes, input_shape=[num_freq_bin, num_time_bin, 3*num_audio_channels], num_filters=24, wd=1e-3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = SGD(lr=max_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy']) #ori\n",
    "\n",
    "model.summary()\n",
    "\n",
    "lr_scheduler = LR_WarmRestart(nbatch=np.ceil(sample_num/batch_size), Tmult=2,\n",
    "                              initial_lr=max_lr, min_lr=max_lr*1e-4,\n",
    "                              epochs_restart = [3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0]) \n",
    "save_path = experiments + \"/model-mixup_alpha:{}-max_lr:{}-total_epochs:{}-no:{}.hdf5\".format(mixup_alpha, max_lr, num_epochs, no)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(save_path, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks = [lr_scheduler, checkpoint]\n",
    "\n",
    "train_data_generator = Generator_balanceclass_timefreqmask_nocropping_splitted(feat_path, train_csv, total_csv, experiments, num_freq_bin, \n",
    "                              batch_size=batch_size,\n",
    "                              alpha=mixup_alpha, splitted_num=4)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_data_generator,\n",
    "                              validation_data=(data_val, y_val),\n",
    "                              epochs=num_epochs, \n",
    "                              verbose=1, \n",
    "                              workers=4,\n",
    "                              max_queue_size = 100,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=np.ceil(sample_num/batch_size)\n",
    "                              ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample data, to keep all three classes have similar number of training samples\n",
    "total_csv = balance_class_data(train_csv, experiments)\n",
    "\n",
    "num_audio_channels = 2\n",
    "num_freq_bin = 128\n",
    "num_time_bin = 461\n",
    "num_classes = 3\n",
    "max_lr = 0.1\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "mixup_alpha = 0.4\n",
    "sample_num = len(open(train_csv, 'r').readlines()) - 1\n",
    "no = 5\n",
    "\n",
    "\n",
    "data_val, y_val = load_data_2020(feat_path, val_csv, num_freq_bin, 'logmel')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "model = model_mobnet(num_classes, input_shape=[num_freq_bin, num_time_bin, 3*num_audio_channels], num_filters=24, wd=1e-3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = SGD(lr=max_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy']) #ori\n",
    "\n",
    "model.summary()\n",
    "\n",
    "lr_scheduler = LR_WarmRestart(nbatch=np.ceil(sample_num/batch_size), Tmult=2,\n",
    "                              initial_lr=max_lr, min_lr=max_lr*1e-4,\n",
    "                              epochs_restart = [3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0]) \n",
    "save_path = experiments + \"/model-mixup_alpha:{}-max_lr:{}-total_epochs:{}-no:{}.hdf5\".format(mixup_alpha, max_lr, num_epochs, no)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(save_path, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks = [lr_scheduler, checkpoint]\n",
    "\n",
    "train_data_generator = Generator_balanceclass_timefreqmask_nocropping_splitted(feat_path, train_csv, total_csv, experiments, num_freq_bin, \n",
    "                              batch_size=batch_size,\n",
    "                              alpha=mixup_alpha, splitted_num=4)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_data_generator,\n",
    "                              validation_data=(data_val, y_val),\n",
    "                              epochs=num_epochs, \n",
    "                              verbose=1, \n",
    "                              workers=4,\n",
    "                              max_queue_size = 100,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=np.ceil(sample_num/batch_size)\n",
    "                              ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEl 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample data, to keep all three classes have similar number of training samples\n",
    "total_csv = balance_class_data(train_csv, experiments)\n",
    "\n",
    "num_audio_channels = 2\n",
    "num_freq_bin = 128\n",
    "num_time_bin = 461\n",
    "num_classes = 3\n",
    "max_lr = 0.1\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "mixup_alpha = 0.1\n",
    "sample_num = len(open(train_csv, 'r').readlines()) - 1\n",
    "no = 6\n",
    "\n",
    "\n",
    "data_val, y_val = load_data_2020(feat_path, val_csv, num_freq_bin, 'logmel')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "model = model_mobnet(num_classes, input_shape=[num_freq_bin, num_time_bin, 3*num_audio_channels], num_filters=24, wd=1e-3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = SGD(lr=max_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy']) #ori\n",
    "\n",
    "model.summary()\n",
    "\n",
    "lr_scheduler = LR_WarmRestart(nbatch=np.ceil(sample_num/batch_size), Tmult=2,\n",
    "                              initial_lr=max_lr, min_lr=max_lr*1e-4,\n",
    "                              epochs_restart = [3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0]) \n",
    "save_path = experiments + \"/model-mixup_alpha:{}-max_lr:{}-total_epochs:{}-no:{}.hdf5\".format(mixup_alpha, max_lr, num_epochs, no)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(save_path, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks = [lr_scheduler, checkpoint]\n",
    "\n",
    "train_data_generator = Generator_balanceclass_timefreqmask_nocropping_splitted(feat_path, train_csv, total_csv, experiments, num_freq_bin, \n",
    "                              batch_size=batch_size,\n",
    "                              alpha=mixup_alpha, splitted_num=4)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_data_generator,\n",
    "                              validation_data=(data_val, y_val),\n",
    "                              epochs=num_epochs, \n",
    "                              verbose=1, \n",
    "                              workers=4,\n",
    "                              max_queue_size = 100,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=np.ceil(sample_num/batch_size)\n",
    "                              ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample data, to keep all three classes have similar number of training samples\n",
    "total_csv = balance_class_data(train_csv, experiments)\n",
    "\n",
    "num_audio_channels = 2\n",
    "num_freq_bin = 128\n",
    "num_time_bin = 461\n",
    "num_classes = 3\n",
    "max_lr = 0.05\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "mixup_alpha = 0.4\n",
    "sample_num = len(open(train_csv, 'r').readlines()) - 1\n",
    "no = 7\n",
    "\n",
    "\n",
    "data_val, y_val = load_data_2020(feat_path, val_csv, num_freq_bin, 'logmel')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "model = model_mobnet(num_classes, input_shape=[num_freq_bin, num_time_bin, 3*num_audio_channels], num_filters=24, wd=1e-3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = SGD(lr=max_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy']) #ori\n",
    "\n",
    "model.summary()\n",
    "\n",
    "lr_scheduler = LR_WarmRestart(nbatch=np.ceil(sample_num/batch_size), Tmult=2,\n",
    "                              initial_lr=max_lr, min_lr=max_lr*1e-4,\n",
    "                              epochs_restart = [3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0]) \n",
    "save_path = experiments + \"/model-mixup_alpha:{}-max_lr:{}-total_epochs:{}-no:{}.hdf5\".format(mixup_alpha, max_lr, num_epochs, no)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(save_path, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks = [lr_scheduler, checkpoint]\n",
    "\n",
    "train_data_generator = Generator_balanceclass_timefreqmask_nocropping_splitted(feat_path, train_csv, total_csv, experiments, num_freq_bin, \n",
    "                              batch_size=batch_size,\n",
    "                              alpha=mixup_alpha, splitted_num=4)()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_data_generator,\n",
    "                              validation_data=(data_val, y_val),\n",
    "                              epochs=num_epochs, \n",
    "                              verbose=1, \n",
    "                              workers=4,\n",
    "                              max_queue_size = 100,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=np.ceil(sample_num/batch_size)\n",
    "                              ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d20-keras] *",
   "language": "python",
   "name": "conda-env-d20-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
